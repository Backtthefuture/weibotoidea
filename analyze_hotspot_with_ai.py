#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIåˆ†æå¾®åšçƒ­ç‚¹å¹¶ç”Ÿæˆäº§å“åˆ›æ„
"""

import json
import os
import re
import sys
from datetime import datetime


def load_search_results():
    """åŠ è½½æ‰€æœ‰æœç´¢ç»“æœæ–‡ä»¶"""
    print("æ­£åœ¨åŠ è½½æœç´¢ç»“æœ...")

    search_results = []
    result_files = [f for f in os.listdir('.') if f.startswith('search_results_') and f.endswith('.json')]

    if not result_files:
        print("âŒ æœªæ‰¾åˆ°æœç´¢ç»“æœæ–‡ä»¶")
        print("è¯·ç¡®ä¿æ–‡ä»¶åä¸º: search_results_XX.json")
        return []

    print(f"æ‰¾åˆ° {len(result_files)} ä¸ªç»“æœæ–‡ä»¶")

    for result_file in sorted(result_files):
        try:
            with open(result_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æå–æ–‡ä»¶åä¸­çš„æ’å
            match = re.search(r'search_results_(\d+)\.json', result_file)
            rank = int(match.group(1)) if match else 0

            search_results.append({
                'rank': rank,
                'filename': result_file,
                'data': data,
                'title': data.get('title', f'çƒ­ç‚¹#{rank}'),
                'content': data.get('content', '')
            })

            print(f"  âœ… å·²åŠ è½½: {result_file} (æ’å: #{rank})")

        except Exception as e:
            print(f"  âŒ åŠ è½½å¤±è´¥ {result_file}: {e}")

    # æŒ‰æ’åæ’åº
    search_results.sort(key=lambda x: x['rank'])

    print(f"âœ… æˆåŠŸåŠ è½½ {len(search_results)} ä¸ªæœç´¢ç»“æœ")
    return search_results


def load_hotspot_queries():
    """åŠ è½½çƒ­æœæŸ¥è¯¢åˆ—è¡¨"""
    try:
        with open('weibo_search_queries.json', 'r', encoding='utf-8') as f:
            queries = json.load(f)
        return queries
    except Exception as e:
        print(f"âŒ åŠ è½½çƒ­æœæŸ¥è¯¢å¤±è´¥: {e}")
        return []


def extract_search_snippet(search_data):
    """ä»æœç´¢ç»“æœä¸­æå–æ‘˜è¦"""
    if not search_data:
        return "æš‚æ— æœç´¢ç»“æœ"

    # æ ¹æ®ä¸åŒçš„æ•°æ®ç»“æ„æå–ä¿¡æ¯
    if isinstance(search_data, dict):
        # å¦‚æœæ˜¯å•ä¸ªç»“æœ
        snippet = search_data.get('snippet', '') or search_data.get('content', '')
        if snippet:
            return snippet[:500]  # é™åˆ¶é•¿åº¦

        # å°è¯•å…¶ä»–å­—æ®µ
        for key in ['description', 'summary', 'text', 'body']:
            if key in search_data:
                return str(search_data[key])[:500]

    elif isinstance(search_data, list) and len(search_data) > 0:
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–å‰å‡ ä¸ª
        snippets = []
        for item in search_data[:3]:
            if isinstance(item, dict):
                snippet = item.get('snippet', '') or item.get('content', '') or item.get('description', '')
                if snippet:
                    snippets.append(snippet)
        return ' | '.join(snippets)[:500]

    return "æœç´¢ç»“æœå†…å®¹è¾ƒå°‘"


def generate_ai_analysis_prompt(hotspot_data, search_summary):
    """ç”ŸæˆAIåˆ†ææç¤º"""
    title = hotspot_data.get('title', 'æœªçŸ¥çƒ­ç‚¹')

    prompt = f"""è¯·åˆ†æä»¥ä¸‹å¾®åšçƒ­æœè¯é¢˜ï¼Œå¹¶ä»"æœ‰è¶£"å’Œ"æœ‰ç”¨"ä¸¤ä¸ªè§’åº¦è¯„ä¼°ç”Ÿæˆå°äº§å“çš„å¯èƒ½æ€§ã€‚

## çƒ­æœè¯é¢˜
{title}

## èƒŒæ™¯ä¿¡æ¯
{search_summary}

## è¯„ä¼°æ ‡å‡†

### 1. æœ‰è¶£åº¦ï¼ˆæ»¡åˆ†80åˆ†ï¼‰
- è¯é¢˜æ˜¯å¦æ–°é¢–ã€æœ‰åˆ›æ„ï¼Ÿ
- æ˜¯å¦èƒ½å¼•å‘ç”¨æˆ·å¥½å¥‡å¿ƒå’Œå‚ä¸æ¬²ï¼Ÿ
- æ˜¯å¦æœ‰å¨±ä¹æ€§ã€ä¼ æ’­æ€§ï¼Ÿ
- æ˜¯å¦èƒ½åˆ›é€ ç‹¬ç‰¹çš„ç”¨æˆ·ä½“éªŒï¼Ÿ

### 2. æœ‰ç”¨åº¦ï¼ˆæ»¡åˆ†20åˆ†ï¼‰
- æ˜¯å¦èƒ½è§£å†³å®é™…é—®é¢˜ï¼Ÿ
- æ˜¯å¦æœ‰å®ç”¨ä»·å€¼ï¼Ÿ
- æ˜¯å¦èƒ½æé«˜æ•ˆç‡æˆ–æä¾›ä¾¿åˆ©ï¼Ÿ

## è¾“å‡ºè¦æ±‚

è¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰ï¼š

```json
{{
  "fun_score": 0-80,  // æœ‰è¶£åº¦è¯„åˆ†ï¼ˆ0-80åˆ†ï¼‰
  "fun_reason": "æœ‰è¶£åº¦è¯„åˆ†ç†ç”±",
  "useful_score": 0-20,  // æœ‰ç”¨åº¦è¯„åˆ†ï¼ˆ0-20åˆ†ï¼‰
  "useful_reason": "æœ‰ç”¨åº¦è¯„åˆ†ç†ç”±",
  "total_score": 0-100,  // æ€»åˆ†
  "has_idea": true/false,  // æ˜¯å¦ç”Ÿæˆäº§å“åˆ›æ„
  "product": {{
    "name": "äº§å“åç§°",
    "features": "æ ¸å¿ƒåŠŸèƒ½",
    "target_users": "ç›®æ ‡ç”¨æˆ·",
    "description": "äº§å“æè¿°ï¼ˆ50å­—ä»¥å†…ï¼‰"
  }},
  "summary": "å…³é”®äº‹ä»¶è„‰ç»œï¼ˆ100å­—ä»¥å†…ï¼‰",
  "analysis_notes": "åˆ†æå¤‡æ³¨"
}}
```

**é‡è¦**ï¼šå¦‚æœæ€»åˆ† < 60åˆ†ï¼Œè¯·å°† has_idea è®¾ä¸º falseï¼Œproduct è®¾ä¸º nullã€‚

è¯·åˆ†æå¹¶è¿”å›JSONç»“æœï¼š"""

    return prompt


def save_analysis_prompts(search_results, hotspot_queries):
    """ä¿å­˜æ‰€æœ‰AIåˆ†ææç¤º"""
    prompts_dir = 'analysis_prompts'
    os.makedirs(prompts_dir, exist_ok=True)

    prompts_data = []

    for i, result in enumerate(search_results):
        rank = result['rank']
        title = result['title']

        # åŒ¹é…å¯¹åº”çš„çƒ­æœæŸ¥è¯¢
        hotspot_query = None
        for q in hotspot_queries:
            if q['rank'] == rank:
                hotspot_query = q
                break

        if not hotspot_query:
            hotspot_query = {'title': title, 'rank': rank}

        # æå–æœç´¢æ‘˜è¦
        search_summary = extract_search_snippet(result['data'])

        # ç”ŸæˆAIæç¤º
        prompt = generate_ai_analysis_prompt(hotspot_query, search_summary)

        # ä¿å­˜æç¤ºåˆ°æ–‡ä»¶
        prompt_file = os.path.join(prompts_dir, f'prompt_{rank:02d}.txt')
        try:
            with open(prompt_file, 'w', encoding='utf-8') as f:
                f.write(prompt)

            prompts_data.append({
                'rank': rank,
                'title': title,
                'prompt_file': prompt_file,
                'hotspot_data': hotspot_query,
                'search_summary': search_summary
            })

            print(f"  âœ… å·²ç”Ÿæˆ: {prompt_file}")

        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥ prompt_{rank:02d}.txt: {e}")

    print(f"âœ… å…±ç”Ÿæˆ {len(prompts_data)} ä¸ªAIåˆ†ææç¤º")

    # ä¿å­˜ç´¢å¼•æ–‡ä»¶
    index_file = 'analysis_prompts_index.json'
    try:
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(prompts_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… æç¤ºç´¢å¼•å·²ä¿å­˜: {index_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜ç´¢å¼•å¤±è´¥: {e}")

    return prompts_data


def create_analysis_instructions(prompts_data):
    """åˆ›å»ºåˆ†ææ“ä½œè¯´æ˜"""
    instructions = f"""# AIåˆ†ææ“ä½œè¯´æ˜

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ¦‚è¿°

æœ¬æ­¥éª¤ä½¿ç”¨Claude AIåˆ†ææ¯ä¸ªçƒ­æœè¯é¢˜ï¼Œç”Ÿæˆäº§å“åˆ›æ„ã€‚

## åˆ†ææ­¥éª¤

å¯¹äºæ¯ä¸ªçƒ­æœè¯é¢˜ï¼Œéœ€è¦ï¼š

1. è¯»å–æç¤ºæ–‡ä»¶ï¼ˆä½äº analysis_prompts/ ç›®å½•ï¼‰
2. å°†æç¤ºå†…å®¹å‘é€ç»™Claude AI
3. æ”¶é›†AIè¿”å›çš„JSONæ ¼å¼åˆ†æç»“æœ
4. ä¿å­˜ç»“æœåˆ° `analysis_results/result_{{rank}}.json`

## æç¤ºæ–‡ä»¶åˆ—è¡¨

æ€»å…±éœ€è¦åˆ†æ: {len(prompts_data)} ä¸ªçƒ­æœè¯é¢˜

"""

    for prompt_info in prompts_data[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
        instructions += f"""
### #{prompt_info['rank']} - {prompt_info['title']}

- **æç¤ºæ–‡ä»¶**: `{prompt_info['prompt_file']}`
- **è¾“å‡ºæ–‡ä»¶**: `analysis_results/result_{prompt_info['rank']:02d}.json`
- **æ‰§è¡Œæ–¹å¼**: å°†æç¤ºæ–‡ä»¶å†…å®¹å‘é€ç»™Claude AI
- **æœŸæœ›è¾“å‡º**: JSONæ ¼å¼åˆ†æç»“æœ

"""

    if len(prompts_data) > 10:
        instructions += f"\n... è¿˜æœ‰ {len(prompts_data) - 10} ä¸ªè¯é¢˜å¾…åˆ†æ\n"

    instructions += """
## AIåˆ†ææŒ‡å¯¼åŸåˆ™

### è¯„åˆ†æ ‡å‡†

1. **æœ‰è¶£åº¦ï¼ˆ80åˆ†ï¼‰**
   - è¯é¢˜æ–°é¢–æ€§ä¸åˆ›æ„æ€§: 40%
   - ä¼ æ’­æ€§ä¸å¨±ä¹æ€§: 30%
   - ç”¨æˆ·ä½“éªŒç‹¬ç‰¹æ€§: 30%

2. **æœ‰ç”¨åº¦ï¼ˆ20åˆ†ï¼‰**
   - å®ç”¨æ€§: 50%
   - é—®é¢˜è§£å†³èƒ½åŠ›: 50%

### äº§å“åˆ›æ„è¦æ±‚

- **æ€»åˆ†â‰¥60åˆ†**æ‰ä¼šç”Ÿæˆäº§å“åˆ›æ„
- äº§å“åç§°: ç®€æ´æœ‰å¸å¼•åŠ›
- æ ¸å¿ƒåŠŸèƒ½: æ¸…æ™°æ˜ç¡®
- ç›®æ ‡ç”¨æˆ·: å…·ä½“ç²¾å‡†
- äº§å“æè¿°: â‰¤50å­—

### äº‹ä»¶è„‰ç»œæ€»ç»“

- 100å­—ä»¥å†…
- æ¦‚æ‹¬äº‹ä»¶æ ¸å¿ƒ
- çªå‡ºå…³é”®ä¿¡æ¯

## æœŸæœ›è¾“å‡ºæ ¼å¼

```json
{
  "fun_score": 70,
  "fun_reason": "è¯é¢˜æ–°é¢–ï¼Œä¼ æ’­æ€§å¼º...",
  "useful_score": 15,
  "useful_reason": "å¯è§£å†³ç”¨æˆ·å®é™…é—®é¢˜...",
  "total_score": 85,
  "has_idea": true,
  "product": {
    "name": "äº§å“åç§°",
    "features": "æ ¸å¿ƒåŠŸèƒ½",
    "target_users": "ç›®æ ‡ç”¨æˆ·",
    "description": "äº§å“æè¿°ï¼ˆ50å­—ä»¥å†…ï¼‰"
  },
  "summary": "å…³é”®äº‹ä»¶è„‰ç»œæ€»ç»“ï¼ˆ100å­—ä»¥å†…ï¼‰",
  "analysis_notes": "å…¶ä»–åˆ†æå¤‡æ³¨"
}
```

## æ‰‹åŠ¨åˆ†æå‘½ä»¤

å¦‚æœæ‰‹åŠ¨æ‰§è¡Œï¼Œå¯ä»¥è¿è¡Œï¼š

```bash
python manual_ai_analysis.py
```

## ä¸‹ä¸€æ­¥

æ‰€æœ‰AIåˆ†æå®Œæˆåï¼Œæ‰§è¡Œï¼š

```bash
python generate_html_report.py
```

ç”Ÿæˆæœ€ç»ˆHTMLæŠ¥å‘Šã€‚
"""

    # ä¿å­˜è¯´æ˜æ–‡ä»¶
    instructions_file = 'AI_ANALYSIS_INSTRUCTIONS.md'
    try:
        with open(instructions_file, 'w', encoding='utf-8') as f:
            f.write(instructions)
        print(f"âœ… åˆ†æè¯´æ˜å·²ä¿å­˜: {instructions_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜è¯´æ˜å¤±è´¥: {e}")

    return instructions_file


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AIåˆ†æ - å¾®åšçƒ­ç‚¹äº§å“åˆ›æ„ç”Ÿæˆå™¨")
    print("=" * 60)
    print(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # åŠ è½½çƒ­æœæŸ¥è¯¢
    print("ã€æ­¥éª¤1/3ã€‘åŠ è½½çƒ­æœæŸ¥è¯¢...")
    hotspot_queries = load_hotspot_queries()
    if not hotspot_queries:
        print("\nâŒ æœªæ‰¾åˆ°çƒ­æœæŸ¥è¯¢æ•°æ®")
        print("è¯·å…ˆè¿è¡Œ: python fetch_weibo_hotspot.py")
        return 1

    # åŠ è½½æœç´¢ç»“æœ
    print("\nã€æ­¥éª¤2/3ã€‘åŠ è½½æœç´¢ç»“æœ...")
    search_results = load_search_results()
    if not search_results:
        print("\nâŒ æœªæ‰¾åˆ°æœç´¢ç»“æœæ•°æ®")
        print("è¯·å…ˆå®Œæˆæœç´¢æ­¥éª¤")
        return 1

    # ç”ŸæˆAIåˆ†ææç¤º
    print("\nã€æ­¥éª¤3/3ã€‘ç”ŸæˆAIåˆ†ææç¤º...")
    prompts_data = save_analysis_prompts(search_results, hotspot_queries)

    if not prompts_data:
        print("\nâŒ æœªèƒ½ç”ŸæˆAIåˆ†ææç¤º")
        return 1

    # åˆ›å»ºåˆ†æè¯´æ˜
    create_analysis_instructions(prompts_data)

    print("\nâœ… AIåˆ†æå‡†å¤‡å·¥ä½œå®Œæˆï¼")
    print("ğŸ“ å·²åˆ›å»º analysis_prompts/ ç›®å½•")
    print("ğŸ“„ è¯·æŸ¥çœ‹ AI_ANALYSIS_INSTRUCTIONS.md äº†è§£è¯¦ç»†æ­¥éª¤")
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
    print("   æ–¹æ³•1: æ‰‹åŠ¨å°†æ¯ä¸ªæç¤ºæ–‡ä»¶å‘é€ç»™Claude AI")
    print("   æ–¹æ³•2: ä½¿ç”¨Claude Codeæ‰¹é‡åˆ†æ")
    print("\n   æ”¶é›†æ‰€æœ‰AIåˆ†æç»“æœåï¼Œè¿è¡Œ:")
    print("   python generate_html_report.py")

    return 0


if __name__ == "__main__":
    sys.exit(main())
